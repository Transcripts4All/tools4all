{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Transcripts4All/tools4all/blob/main/whisper-diarization.ipynb)"
      ],
      "metadata": {
        "id": "colab"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 1:\n",
        "# Execute the following task and upload an audio file to the content directory while you wait for the task to complete."
      ],
      "metadata": {
        "id": "step1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/MahmoudAshraf97/whisper-diarization\n",
        "!pip install git+https://github.com/m-bain/whisperX.git@78dcfaab51005aa703ee21375f81ed31bc248560\n",
        "!pip install --no-build-isolation nemo_toolkit[asr]==1.22.0\n",
        "!pip install --no-deps git+https://github.com/facebookresearch/demucs#egg=demucs\n",
        "!pip install dora-search \"lameenc>=1.2\" openunmix\n",
        "!pip install deepmultilingualpunctuation\n",
        "!pip install wget pydub"
      ],
      "metadata": {
        "id": "setup"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 2:\n",
        "# ^ !!! WAIT FOR ABOVE TASK TO COMPLETE !!! ^\n",
        "# ^ !!! BEFORE RESTARTING RUNTIME !!! ^\n",
        "\n",
        "# Step 3:\n",
        "# Once the above task has completed and the audio file has successfully been uploaded to the content directory, execute the follow task."
      ],
      "metadata": {
        "id": "step23"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import glob, os\n",
        "audioFiles = glob.glob(\"/content/*.*\")\n",
        "os.chdir(\"/content/whisper-diarization\")\n",
        "for i in range(len(audioFiles)):\n",
        "  for audioFile in glob.glob(audioFiles[i]):\n",
        "    baseFile = os.path.splitext(audioFile)[0]\n",
        "    !python diarize_parallel.py --whisper-model large-v3 -a \"$audioFile\"\n",
        "    !rm \"$audioFile\"\n",
        "    !zip \"$baseFile\".zip \"$baseFile\".srt \"$baseFile\".txt\n",
        "    !rm \"$baseFile\".srt \"$baseFile\".txt"
      ],
      "metadata": {
        "id": "generate"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 4:\n",
        "# Download the /content/Transcript.zip file."
      ],
      "metadata": {
        "id": "step4"
      }
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "private_outputs": true,
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
